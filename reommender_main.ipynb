{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "966dddec-2096-4619-a6d0-a58334f95edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CB.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06a5e2e-1488-4002-a11b-b9b7a3cfaf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run CF.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319c5ee-04b5-452b-91d1-77acab57814f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Batch Testing #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3140e-f172-4234-8867-5b7bf239619b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Collaborative Filtering Recommender Testing #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092bfeee-b7e7-478a-9382-063e8d6ac3d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Testing Functions ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1bca3e0-f584-4354-91c3-fa65eaed762d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hit_ratio(testset, n):\n",
    "    '''\n",
    "        Function that calculates the hit ratio for a CF testset. The function does so by gathering n recommendations and \n",
    "        checking if the target value is within the list of recommendations.\n",
    "        \n",
    "        Inputs:\n",
    "            -     testset      :  a pre-defined test-set\n",
    "            -        n         :  the number of recommendations to extract from the recommender\n",
    "            \n",
    "        Outputs:\n",
    "            - top_n_rec_results:  top n recommendations issued by the recommender\n",
    "            -    hit ratio     :  hit ration calculated for the test set\n",
    "    '''\n",
    "    \n",
    "    # Define place-holders\n",
    "    hits = 0\n",
    "    n_records = 0\n",
    "    top_n_rec_results = {}\n",
    "    \n",
    "    # Gather recommendations\n",
    "    for user in testset.index:\n",
    "        actual = testset.loc[user, testset.columns[-1]]\n",
    "        rec_list = CF_recommender(user, n=n, testset=testset.iloc[:,:-1])\n",
    "        \n",
    "        # Define hits counter\n",
    "        hits_per_user = 0\n",
    "        for course_taken in actual:\n",
    "            if (course_taken in rec_list):\n",
    "                hits_per_user +=1\n",
    "            \n",
    "            # Add records manually\n",
    "            #  This approach allows for mixed testsets\n",
    "            n_records += 1\n",
    "\n",
    "\n",
    "        # Add to number of hits\n",
    "        hits += hits_per_user\n",
    "        \n",
    "        # Build object\n",
    "        top_n_rec_results[user] = {\"actual\": actual,\n",
    "                                   \"recommended\": rec_list,\n",
    "                                   \"hits\": hits_per_user\n",
    "                                }\n",
    "    \n",
    "    # Process results\n",
    "    hit_ratio = hits/n_records\n",
    "\n",
    "    return top_n_rec_results, hit_ratio\n",
    "        \n",
    "def tabulate_hit_ratio_n_range (rec_results, n_start, n_stop):\n",
    "    \n",
    "    '''\n",
    "        Function that tabulates the hit ratio for recommender results. Because of the way in which\n",
    "        recommendations are processed by the CF, it is possible to get the highest nubmer of recommendations \n",
    "        needed and simply compute the results for the lower values.\n",
    "        \n",
    "        Inputs:\n",
    "        -  rec_results    :  results issued by the recommender\n",
    "        -  n_start        :  start value for tabulation\n",
    "        -  n_stop         :  stop value for tabulation\n",
    "        \n",
    "        Outputs:\n",
    "        - printed hit ratio stats\n",
    "    '''\n",
    "    \n",
    "    for n in range(n_start, n_stop+1):\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(f\"Statistics for n={n}\")\n",
    "        \n",
    "        batch_hit_count = 0\n",
    "        course_count = 0\n",
    "        for user in rec_results:   \n",
    "#             print(user)\n",
    "            batch_list = list(rec_results[user][\"recommended\"].keys())[:n]\n",
    "            for course in rec_results[user][\"actual\"]:\n",
    "                # Record count for course completed\n",
    "                course_count +=1 \n",
    "                \n",
    "                if course in batch_list:                    \n",
    "#                     print(f\"{course} in {batch_list}\")\n",
    "                    batch_hit_count +=1 \n",
    "                \n",
    "        print(f\"Number of hits: {batch_hit_count}\")\n",
    "#         print(f\"Number of courses: {course_count}\")\n",
    "        print(f\"Hit ratio: {round(batch_hit_count/course_count, 4)}\")\n",
    "    \n",
    "    print(\"-------------------------------------------------\")\n",
    "            \n",
    "def get_MRR_at_n (rec_results, n=10):\n",
    "    '''\n",
    "        Function that calculates the MRR score for the CF recommender.\n",
    "        \n",
    "        Inputs:\n",
    "        - rec_results   :  a set of results that have been outputted by the recommender\n",
    "        -     n         :  the n value for which to calculate the MRR (default is 10)\n",
    "        \n",
    "        Outputs:\n",
    "        -    MRR        :  value of MRR at n\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Define list to hold placement of each\n",
    "    #  relevant recommendation\n",
    "    RR = []\n",
    "    \n",
    "    # Loop through recommendations\n",
    "    for user in list(rec_results.keys()):\n",
    "#         print(user)\n",
    "        # Loop through each of the completed courses\n",
    "        actual = rec_results[user][\"actual\"]\n",
    "        for course in actual:\n",
    "            found = False # define a found flag\n",
    "            # Search first n recommended items to find relevant item\n",
    "            for i in range(n):\n",
    "                # When relevant item is found, add its reciprocal rank to the list\n",
    "                if (course == list(rec_results[user][\"recommended\"].keys())[i]):\n",
    "                    # Record reciprocal of ranked recommendation\n",
    "                    found = True\n",
    "                    RR.append(1/(i+1))\n",
    "                    \n",
    "            # If no relevant result is found, append 0\n",
    "            if not found:\n",
    "                RR.append(0)\n",
    "                    \n",
    "    # Calculate the mean                \n",
    "    MRR = sum(RR)/len(RR)\n",
    "    \n",
    "    return MRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361eba2-a7b9-4dca-a515-36f88fe7774c",
   "metadata": {},
   "source": [
    "## Prepare Test Sets ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d7513-ec71-4c89-ab63-f3c81c4a45ed",
   "metadata": {},
   "source": [
    "### *Test Set A* ###\n",
    "Filter database for all users who have completed  one course and check predictions by hiding the completed course information and measure the performance of the CF recommender in relation to the actual course completed by each of these users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbfb4132-bca0-4b92-b1fb-15497e5dd6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>course_id</th>\n",
       "      <th>14.73x</th>\n",
       "      <th>2.01x</th>\n",
       "      <th>3.091x</th>\n",
       "      <th>6.002x</th>\n",
       "      <th>6.00x</th>\n",
       "      <th>7.00x</th>\n",
       "      <th>8.02x</th>\n",
       "      <th>8.MReV</th>\n",
       "      <th>CB22x</th>\n",
       "      <th>CS50x</th>\n",
       "      <th>ER22x</th>\n",
       "      <th>PH207x</th>\n",
       "      <th>PH278x</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid_DI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H130000071</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000715</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000944</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130001577</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130002019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130595975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130596958</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597250</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597647</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597663</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2605 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "course_id   14.73x  2.01x  3.091x  6.002x  6.00x  7.00x  8.02x  8.MReV  CB22x  \\\n",
       "userid_DI                                                                       \n",
       "H130000071     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    1.0   \n",
       "H130000715     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130000944     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130001577     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    1.0   \n",
       "H130002019     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "...            ...    ...     ...     ...    ...    ...    ...     ...    ...   \n",
       "M130595975     NaN    NaN     NaN     1.0    NaN    NaN    NaN     NaN    NaN   \n",
       "M130596958     NaN    NaN     NaN     NaN    1.0    NaN    NaN     NaN    NaN   \n",
       "M130597250     NaN    NaN     NaN     NaN    1.0    NaN    NaN     NaN    NaN   \n",
       "M130597647     1.0    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "M130597663     1.0    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "\n",
       "course_id   CS50x  ER22x  PH207x  PH278x  sum  \n",
       "userid_DI                                      \n",
       "H130000071    NaN    NaN     NaN     NaN  1.0  \n",
       "H130000715    1.0    NaN     NaN     NaN  1.0  \n",
       "H130000944    NaN    1.0     NaN     NaN  1.0  \n",
       "H130001577    NaN    NaN     NaN     NaN  1.0  \n",
       "H130002019    NaN    NaN     1.0     NaN  1.0  \n",
       "...           ...    ...     ...     ...  ...  \n",
       "M130595975    NaN    NaN     NaN     NaN  1.0  \n",
       "M130596958    NaN    NaN     NaN     NaN  1.0  \n",
       "M130597250    NaN    NaN     NaN     NaN  1.0  \n",
       "M130597647    NaN    NaN     NaN     NaN  1.0  \n",
       "M130597663    NaN    NaN     NaN     NaN  1.0  \n",
       "\n",
       "[2605 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsetA = test_pt[test_pt[\"sum\"]==1].copy()\n",
    "testsetA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4cb7f3a-0196-4799-ae67-218628476dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list_testsetA = list(testsetA.index)\n",
    "# user_list_testsetA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95983568-94cb-4ef6-a7a0-6c8cf1f47d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values before \n",
    "testsetA[\"course_completed_by_user\"] = [list(testsetA.columns[np.where(testsetA.loc[user, testsetA.columns[:-1]]==1)[0]]) for user in testsetA.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e186c97-2e02-4631-b349-7f855c8a33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all 1 values to 0\n",
    "for col in testsetA.columns[:-1]:\n",
    "    testsetA[col] = np.where(testsetA[col]==1, 0, testsetA[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "907f006f-e215-41c2-87cc-9f863eff8a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>course_id</th>\n",
       "      <th>14.73x</th>\n",
       "      <th>2.01x</th>\n",
       "      <th>3.091x</th>\n",
       "      <th>6.002x</th>\n",
       "      <th>6.00x</th>\n",
       "      <th>7.00x</th>\n",
       "      <th>8.02x</th>\n",
       "      <th>8.MReV</th>\n",
       "      <th>CB22x</th>\n",
       "      <th>CS50x</th>\n",
       "      <th>ER22x</th>\n",
       "      <th>PH207x</th>\n",
       "      <th>PH278x</th>\n",
       "      <th>sum</th>\n",
       "      <th>course_completed_by_user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid_DI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H130000071</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[CB22x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000715</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[CS50x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000944</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ER22x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130001577</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[CB22x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130002019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[PH207x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130595975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6.002x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130596958</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6.00x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597250</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6.00x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597647</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[14.73x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597663</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[14.73x]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2605 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "course_id   14.73x  2.01x  3.091x  6.002x  6.00x  7.00x  8.02x  8.MReV  CB22x  \\\n",
       "userid_DI                                                                       \n",
       "H130000071     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    0.0   \n",
       "H130000715     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130000944     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130001577     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    0.0   \n",
       "H130002019     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "...            ...    ...     ...     ...    ...    ...    ...     ...    ...   \n",
       "M130595975     NaN    NaN     NaN     0.0    NaN    NaN    NaN     NaN    NaN   \n",
       "M130596958     NaN    NaN     NaN     NaN    0.0    NaN    NaN     NaN    NaN   \n",
       "M130597250     NaN    NaN     NaN     NaN    0.0    NaN    NaN     NaN    NaN   \n",
       "M130597647     0.0    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "M130597663     0.0    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "\n",
       "course_id   CS50x  ER22x  PH207x  PH278x  sum course_completed_by_user  \n",
       "userid_DI                                                               \n",
       "H130000071    NaN    NaN     NaN     NaN  0.0                  [CB22x]  \n",
       "H130000715    0.0    NaN     NaN     NaN  0.0                  [CS50x]  \n",
       "H130000944    NaN    0.0     NaN     NaN  0.0                  [ER22x]  \n",
       "H130001577    NaN    NaN     NaN     NaN  0.0                  [CB22x]  \n",
       "H130002019    NaN    NaN     0.0     NaN  0.0                 [PH207x]  \n",
       "...           ...    ...     ...     ...  ...                      ...  \n",
       "M130595975    NaN    NaN     NaN     NaN  0.0                 [6.002x]  \n",
       "M130596958    NaN    NaN     NaN     NaN  0.0                  [6.00x]  \n",
       "M130597250    NaN    NaN     NaN     NaN  0.0                  [6.00x]  \n",
       "M130597647    NaN    NaN     NaN     NaN  0.0                 [14.73x]  \n",
       "M130597663    NaN    NaN     NaN     NaN  0.0                 [14.73x]  \n",
       "\n",
       "[2605 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsetA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c16e7d7e-fd76-488a-9abb-e0d9c5bc06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testsetA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e4e8f-5ac2-42bf-8279-7efcc6d7e651",
   "metadata": {},
   "source": [
    "### *Test Set B* ###\n",
    "Filter database of all users who have completed two courses (i.e., the maximum number of courses completed by any user in the test) and check predictions in two ways:\n",
    "1) hide all courses and check recommendations for two course\n",
    "2) hide one course at a time and check recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "beb225e6-a3a6-45bb-a173-779b1336bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsetB = test_pt[test_pt[\"sum\"]==2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e05f54-8b7f-456d-bff9-1ba0ab75c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsetB_user_list = testsetB.index\n",
    "# testsetB_user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3f2919-87a0-4990-829d-92378dd491b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>course_id</th>\n",
       "      <th>14.73x</th>\n",
       "      <th>2.01x</th>\n",
       "      <th>3.091x</th>\n",
       "      <th>6.002x</th>\n",
       "      <th>6.00x</th>\n",
       "      <th>7.00x</th>\n",
       "      <th>8.02x</th>\n",
       "      <th>8.MReV</th>\n",
       "      <th>CB22x</th>\n",
       "      <th>CS50x</th>\n",
       "      <th>ER22x</th>\n",
       "      <th>PH207x</th>\n",
       "      <th>PH278x</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid_DI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H130002196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130011763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130020479</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130030300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130030879</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130556674</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130566106</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130570542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130573400</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130577916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "course_id   14.73x  2.01x  3.091x  6.002x  6.00x  7.00x  8.02x  8.MReV  CB22x  \\\n",
       "userid_DI                                                                       \n",
       "H130002196     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130011763     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130020479     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130030300     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130030879     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "...            ...    ...     ...     ...    ...    ...    ...     ...    ...   \n",
       "M130556674     NaN    1.0     1.0     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "M130566106     NaN    NaN     NaN     NaN    1.0    NaN    1.0     NaN    NaN   \n",
       "M130570542     NaN    NaN     NaN     NaN    NaN    NaN    1.0     1.0    NaN   \n",
       "M130573400     NaN    NaN     NaN     1.0    NaN    NaN    1.0     NaN    NaN   \n",
       "M130577916     NaN    NaN     1.0     NaN    NaN    1.0    NaN     NaN    NaN   \n",
       "\n",
       "course_id   CS50x  ER22x  PH207x  PH278x  sum  \n",
       "userid_DI                                      \n",
       "H130002196    NaN    1.0     NaN     1.0  2.0  \n",
       "H130011763    NaN    1.0     NaN     1.0  2.0  \n",
       "H130020479    NaN    1.0     NaN     1.0  2.0  \n",
       "H130030300    NaN    1.0     NaN     1.0  2.0  \n",
       "H130030879    NaN    1.0     NaN     1.0  2.0  \n",
       "...           ...    ...     ...     ...  ...  \n",
       "M130556674    NaN    NaN     NaN     NaN  2.0  \n",
       "M130566106    NaN    NaN     NaN     NaN  2.0  \n",
       "M130570542    NaN    NaN     NaN     NaN  2.0  \n",
       "M130573400    NaN    NaN     NaN     NaN  2.0  \n",
       "M130577916    NaN    NaN     NaN     NaN  2.0  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsetB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b506d33c-9dbe-4603-ae0a-9388bd4b4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values before rewriting table\n",
    "courses_selected = [list(testsetB.columns[np.where(testsetB.loc[user, testsetB.columns[:-1]]==1)[0]]) for user in testsetB_user_list]\n",
    "\n",
    "# Transform course information into np.array for ease of processing\n",
    "# courses_selected = np.array(courses_selected) \n",
    "\n",
    "# Check output\n",
    "# courses_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0d8d72f-579a-43a9-bd90-6f074ed2ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add course information to dataframe before modifying values\n",
    "testsetB[\"actual_course\"] = courses_selected\n",
    "# testsetB[\"actual_course_2\"] = courses_selected[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4199309d-5597-46ce-9455-2b1dadb92327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all non-zero values to 0\n",
    "for col in testsetB.columns[:-1]:\n",
    "    testsetB[col] = np.where((testsetB[col]==1) | (testsetB[col]==2), 0, testsetB[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d47cbce0-212a-42e8-ac6d-471bc490ddec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>course_id</th>\n",
       "      <th>14.73x</th>\n",
       "      <th>2.01x</th>\n",
       "      <th>3.091x</th>\n",
       "      <th>6.002x</th>\n",
       "      <th>6.00x</th>\n",
       "      <th>7.00x</th>\n",
       "      <th>8.02x</th>\n",
       "      <th>8.MReV</th>\n",
       "      <th>CB22x</th>\n",
       "      <th>CS50x</th>\n",
       "      <th>ER22x</th>\n",
       "      <th>PH207x</th>\n",
       "      <th>PH278x</th>\n",
       "      <th>sum</th>\n",
       "      <th>actual_course</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid_DI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H130002196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ER22x, PH278x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130011763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ER22x, PH278x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130020479</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ER22x, PH278x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130030300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ER22x, PH278x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130030879</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ER22x, PH278x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130556674</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.01x, 3.091x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130566106</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6.00x, 8.02x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130570542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[8.02x, 8.MReV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130573400</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6.002x, 8.02x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130577916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.091x, 7.00x]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "course_id   14.73x  2.01x  3.091x  6.002x  6.00x  7.00x  8.02x  8.MReV  CB22x  \\\n",
       "userid_DI                                                                       \n",
       "H130002196     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130011763     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130020479     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130030300     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130030879     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "...            ...    ...     ...     ...    ...    ...    ...     ...    ...   \n",
       "M130556674     NaN    0.0     0.0     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "M130566106     NaN    NaN     NaN     NaN    0.0    NaN    0.0     NaN    NaN   \n",
       "M130570542     NaN    NaN     NaN     NaN    NaN    NaN    0.0     0.0    NaN   \n",
       "M130573400     NaN    NaN     NaN     0.0    NaN    NaN    0.0     NaN    NaN   \n",
       "M130577916     NaN    NaN     0.0     NaN    NaN    0.0    NaN     NaN    NaN   \n",
       "\n",
       "course_id   CS50x  ER22x  PH207x  PH278x  sum    actual_course  \n",
       "userid_DI                                                       \n",
       "H130002196    NaN    0.0     NaN     0.0  0.0  [ER22x, PH278x]  \n",
       "H130011763    NaN    0.0     NaN     0.0  0.0  [ER22x, PH278x]  \n",
       "H130020479    NaN    0.0     NaN     0.0  0.0  [ER22x, PH278x]  \n",
       "H130030300    NaN    0.0     NaN     0.0  0.0  [ER22x, PH278x]  \n",
       "H130030879    NaN    0.0     NaN     0.0  0.0  [ER22x, PH278x]  \n",
       "...           ...    ...     ...     ...  ...              ...  \n",
       "M130556674    NaN    NaN     NaN     NaN  0.0  [2.01x, 3.091x]  \n",
       "M130566106    NaN    NaN     NaN     NaN  0.0   [6.00x, 8.02x]  \n",
       "M130570542    NaN    NaN     NaN     NaN  0.0  [8.02x, 8.MReV]  \n",
       "M130573400    NaN    NaN     NaN     NaN  0.0  [6.002x, 8.02x]  \n",
       "M130577916    NaN    NaN     NaN     NaN  0.0  [3.091x, 7.00x]  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsetB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917fda82-9649-4578-9468-5181400a1060",
   "metadata": {},
   "source": [
    "\n",
    "### *Calculate Hit Ratio for Testset A and Tabulate Results* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8204a081-c998-40e1-8f92-9b455c2d3076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testsetA_full_recs, testsetA_overall_hit_ratio = get_hit_ratio(testsetA, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b1a22c5-9c54-47d6-a4eb-eb99763d8026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5225256679767233"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MRR_at_n(testsetA_full_recs, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46d8ffa1-1858-4e91-a968-7a23f8d8f5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49973128598848454"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MRR_at_n(testsetA_full_recs, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afc77499-d0d0-4077-a961-a7efb6f1cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37235989633948846"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MRR_at_n(testsetB_full_recs, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f900e104-451b-4990-8c20-d3bbe2ba2725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3267857142857144"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MRR_at_n(testsetB_full_recs, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b504d554-e367-4864-aab6-8712b4a3fcf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Statistics for n=1\n",
      "Number of hits: 864\n",
      "Hit ratio: 0.3317\n",
      "-------------------------------------------------\n",
      "Statistics for n=2\n",
      "Number of hits: 1340\n",
      "Hit ratio: 0.5144\n",
      "-------------------------------------------------\n",
      "Statistics for n=3\n",
      "Number of hits: 1655\n",
      "Hit ratio: 0.6353\n",
      "-------------------------------------------------\n",
      "Statistics for n=4\n",
      "Number of hits: 1879\n",
      "Hit ratio: 0.7213\n",
      "-------------------------------------------------\n",
      "Statistics for n=5\n",
      "Number of hits: 2073\n",
      "Hit ratio: 0.7958\n",
      "-------------------------------------------------\n",
      "Statistics for n=6\n",
      "Number of hits: 2212\n",
      "Hit ratio: 0.8491\n",
      "-------------------------------------------------\n",
      "Statistics for n=7\n",
      "Number of hits: 2316\n",
      "Hit ratio: 0.8891\n",
      "-------------------------------------------------\n",
      "Statistics for n=8\n",
      "Number of hits: 2408\n",
      "Hit ratio: 0.9244\n",
      "-------------------------------------------------\n",
      "Statistics for n=9\n",
      "Number of hits: 2458\n",
      "Hit ratio: 0.9436\n",
      "-------------------------------------------------\n",
      "Statistics for n=10\n",
      "Number of hits: 2501\n",
      "Hit ratio: 0.9601\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tabulate_hit_ratio_n_range(testsetA_full_recs, 1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1b12d-0c0f-4540-8c88-7bd91520645a",
   "metadata": {},
   "source": [
    "### *Calculate Hit Ratio for Testset B* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2645498c-6534-450b-bd38-cd88efa5a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsetB_full_recs, testsetB_overall_hit_ratio = get_hit_ratio(testsetB, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac907b75-2d12-4e5d-af50-5e26b39b164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Statistics for n=2\n",
      "Number of hits: 63\n",
      "Hit ratio: 0.3214\n",
      "-------------------------------------------------\n",
      "Statistics for n=3\n",
      "Number of hits: 81\n",
      "Hit ratio: 0.4133\n",
      "-------------------------------------------------\n",
      "Statistics for n=4\n",
      "Number of hits: 94\n",
      "Hit ratio: 0.4796\n",
      "-------------------------------------------------\n",
      "Statistics for n=5\n",
      "Number of hits: 113\n",
      "Hit ratio: 0.5765\n",
      "-------------------------------------------------\n",
      "Statistics for n=6\n",
      "Number of hits: 127\n",
      "Hit ratio: 0.648\n",
      "-------------------------------------------------\n",
      "Statistics for n=7\n",
      "Number of hits: 145\n",
      "Hit ratio: 0.7398\n",
      "-------------------------------------------------\n",
      "Statistics for n=8\n",
      "Number of hits: 163\n",
      "Hit ratio: 0.8316\n",
      "-------------------------------------------------\n",
      "Statistics for n=9\n",
      "Number of hits: 170\n",
      "Hit ratio: 0.8673\n",
      "-------------------------------------------------\n",
      "Statistics for n=10\n",
      "Number of hits: 180\n",
      "Hit ratio: 0.9184\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tabulate_hit_ratio_n_range(testsetB_full_recs, 2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe7cd4-d539-4a9b-863c-48ea548f8de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1864294-f2d4-4125-9a48-453aeeb0e86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d2750-4e32-4755-8316-a3d63d2f6561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "93fa7958-b07a-4c56-bd60-7d7ff522c032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>course_id</th>\n",
       "      <th>14.73x</th>\n",
       "      <th>2.01x</th>\n",
       "      <th>3.091x</th>\n",
       "      <th>6.002x</th>\n",
       "      <th>6.00x</th>\n",
       "      <th>7.00x</th>\n",
       "      <th>8.02x</th>\n",
       "      <th>8.MReV</th>\n",
       "      <th>CB22x</th>\n",
       "      <th>CS50x</th>\n",
       "      <th>ER22x</th>\n",
       "      <th>PH207x</th>\n",
       "      <th>PH278x</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid_DI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H130000016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000032</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000035</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H130000059</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597652</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597662</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M130597675</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73728 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "course_id   14.73x  2.01x  3.091x  6.002x  6.00x  7.00x  8.02x  8.MReV  CB22x  \\\n",
       "userid_DI                                                                       \n",
       "H130000016     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    0.0   \n",
       "H130000021     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    0.0   \n",
       "H130000032     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130000035     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "H130000059     NaN    NaN     NaN     NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "...            ...    ...     ...     ...    ...    ...    ...     ...    ...   \n",
       "M130597645     0.0    NaN     NaN     NaN    NaN    0.0    NaN     NaN    NaN   \n",
       "M130597652     NaN    NaN     NaN     0.0    NaN    NaN    NaN     NaN    NaN   \n",
       "M130597662     NaN    NaN     NaN     0.0    NaN    NaN    NaN     NaN    NaN   \n",
       "M130597666     NaN    NaN     NaN     0.0    NaN    NaN    NaN     NaN    NaN   \n",
       "M130597675     NaN    NaN     NaN     NaN    0.0    NaN    NaN     NaN    NaN   \n",
       "\n",
       "course_id   CS50x  ER22x  PH207x  PH278x  sum  \n",
       "userid_DI                                      \n",
       "H130000016    NaN    NaN     NaN     NaN  0.0  \n",
       "H130000021    NaN    NaN     NaN     NaN  0.0  \n",
       "H130000032    0.0    NaN     NaN     NaN  0.0  \n",
       "H130000035    NaN    NaN     NaN     0.0  0.0  \n",
       "H130000059    NaN    NaN     0.0     NaN  0.0  \n",
       "...           ...    ...     ...     ...  ...  \n",
       "M130597645    NaN    NaN     NaN     NaN  0.0  \n",
       "M130597652    NaN    NaN     NaN     NaN  0.0  \n",
       "M130597662    NaN    NaN     NaN     NaN  0.0  \n",
       "M130597666    NaN    NaN     NaN     NaN  0.0  \n",
       "M130597675    NaN    NaN     NaN     NaN  0.0  \n",
       "\n",
       "[73728 rows x 14 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pt[test_pt[\"sum\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0d3a1-0269-4f81-a05c-40ff6cd717a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e03c6f-3a1c-474f-9a77-865611b8e8ac",
   "metadata": {},
   "source": [
    "# Content-Based Recommender Testing #\n",
    "\n",
    "<u>Preceeding Steps (CB.ipynb)</u>:\n",
    "* CB dataframe has been split into CB_train_df and CB_test_df\n",
    "* TF-IDF vectorizer has been initiated\n",
    "* vectorizer was fit to the keywords in CB_train_df and TF-IDF matrix was created\n",
    "* extracted keywords in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d616c84-5fa1-467f-bc79-22c6fdc71c86",
   "metadata": {},
   "source": [
    "### *Define Testing Function* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9567628-1e74-4d2f-9c20-8f4768f1b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "def CB_testing (encoded_course_matrix=tfidf, test_data=test_keywords, vectorizer=vectorizer):\n",
    "    '''\n",
    "        Define function for testing the CB recommender given a set of test keywords. The function first \n",
    "        transforms test keywords into TF-iDF vectors and then calculates the cosine similarity between\n",
    "        each test vector and each training vector in the test set, storing the results in the shape of \n",
    "        a matrix. The testset defined above is based on CB_test_df in CB.ipynb\n",
    "\n",
    "        Inputs:\n",
    "            - tfidf_matrix : matrix created by fitting and transforming the \"training set\"\n",
    "                               (supplied input is the matrix based on the transformed CB_train_df in CB.ipynb)\n",
    "            - test_data    : a (nested) array containing keywords from each of the testsets\n",
    "                               (supplied input is test_keywords, which have been extracted form CB_test_df)\n",
    "            - vectorizer   : vectorizer with which to transform test data\n",
    "                               (supplied fectorizer is the TfidfVectorizer from CB.ipynb)\n",
    "        \n",
    "        Outputs:\n",
    "            - results      : matrix containing a measure of the cosine similarity between each test vector\n",
    "                             and each training vector\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Define dimensions of the results matrix based on the size of the \n",
    "    #  training and test sets\n",
    "    m = encoded_course_matrix.shape[0]\n",
    "    n = len(test_keywords)\n",
    "#     print(m,n)\n",
    "\n",
    "    # Transform test data into vectors for further processing\n",
    "    test_vecs = [vectorizer.transform([record[1]]) for record in test_keywords] # encode the second element of the tuple which contains the keywords themselves\n",
    "    #     print(test_vecs)\n",
    "            \n",
    "    # Define vaiable to hold test rezults by specifying its dimensions\n",
    "    results = np.empty((m,n))   \n",
    "\n",
    "    \n",
    "#     print(cosine_similarity(tfidf_matrix[0], test_vecs[0]))\n",
    "    \n",
    "    # Calculate the cosine similarity between each training and test vector\n",
    "    for i, train_vec in enumerate(encoded_course_matrix):\n",
    "        for j, test_vec in enumerate(test_vecs):\n",
    "            results[i][j] = cosine_similarity(train_vec, test_vec)[0][0]\n",
    "            \n",
    "            \n",
    "    return results\n",
    "\n",
    "# Alternate testing function\n",
    "# def test_cosine_similarity (test_set=test_keywords, encoded_course_matrix=tfidf):\n",
    "   \n",
    "#     # Create matrix to store results\n",
    "#     results = np.empty((tfidf.shape[0], len(test_set)))\n",
    "    \n",
    "#     # Encode the test set\n",
    "#     test_vecs = [encode_query(keywords[1]) for keywords in  test_set] # encode the second element of the tuple which contains the keywords themselves\n",
    "    \n",
    "#     # Populate results matrix in accordance with pre-set structure\n",
    "#     for i, course in enumerate(encoded_course_matrix):\n",
    "#         for j,testvec in enumerate(test_vecs):\n",
    "#             results[i][j] = cosine_similarity(course,testvec)[0][0]\n",
    "    \n",
    "#     return results\n",
    "\n",
    "def CB_tabulate_results(results, test_set = test_keywords, training_set = training_keywords, encoded_course_matrix=tfidf, n=10):\n",
    "    '''\n",
    "        Display information about each item in the test set and the recommendations issued by the subsystem\n",
    "        in a quasi-tabular manner for ease of inspection\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    # Loop through each vector in the test_set\n",
    "    for i in range(results.shape[1]):\n",
    "        \n",
    "        # Isolate the measured closeness to all vectors in the course matrix\n",
    "        top_10_recs = np.argsort(results[:,i])[:-n-1:-1]\n",
    "        \n",
    "        # Output text\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        print(f\"Test_keywords {i}: \")\n",
    "        print(test_set[i], CB_test_df.loc[test_set[i][0], \"Course Number\"],CB_test_df.loc[test_set[i][0], \"Institution\"])\n",
    "        \n",
    "        print(\"\\nRecommendations:\")\n",
    "        for rec in top_10_recs:\n",
    "#             print(rec)\n",
    "            \n",
    "            print(training_set[rec], CB_train_df.iloc[rec, 1]) #, train_df.loc[rec, \"Course Number\"], train_df.loc[rec, \"Institution\"])\n",
    "                                                                                           \n",
    "\n",
    "def CB_subject_accuracy_at_k(results, test_set=test_keywords, training_set=training_keywords, n=5):\n",
    "    '''\n",
    "        Calculate the accuracy with which the recommender chooses courses that have the same subject for any value of n.\n",
    "        \n",
    "        Inputs:\n",
    "            -   results  :  matrix containing recommender results\n",
    "            -   test set :  set of keywords that function as a test set\n",
    "            -       n    :  number of recommendations to issues\n",
    "        \n",
    "        Outputs: \n",
    "            -   accuracy_per_sample : the average accuracy for a set of inputs \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Define variable to store accuracy per test sample\n",
    "    accuracy_per_sample = {}\n",
    "    accuracy_per_sample[n] = {} \n",
    "    \n",
    "    # Number of samples\n",
    "    n_samples = results.shape[1]\n",
    "    \n",
    "    \n",
    "    # Loop through all the test cases\n",
    "    for idx in range(n_samples):\n",
    "        top_n_recs = np.argsort(results[:,idx])[:-n-1:-1]\n",
    "        \n",
    "        # Isolate training subject\n",
    "        target_subject = test_set[idx][1][-1]\n",
    "#         print(test_set[idx][1])\n",
    "#         print(f\"idx: {idx}, target subject: {target_subject}\")\n",
    "            \n",
    "        # Define count variable\n",
    "        count = 0\n",
    "        for rec in top_n_recs:\n",
    "#             print(training_set[rec])\n",
    "#             print(CB_train_df.iloc[rec])\n",
    "#             print(f\"pred: {training_set[rec][1][-1]}\")\n",
    "            if (training_set[rec][1][-1]==target_subject):\n",
    "                count +=1\n",
    "\n",
    "        accuracy_per_sample[n][idx] = count/n\n",
    "        \n",
    "    return accuracy_per_sample\n",
    "\n",
    "def CB_precision_at_k(results, k=5):\n",
    "    # of the number of items recommended, how many are relevant\n",
    "    '''\n",
    "        This function adapts the precision @ k measure in order to provide a measure of the relevance of each recommendation\n",
    "        by calculating the precision of individual keywords and then averaging it out across all recommendations. In short, \n",
    "        this function measures the relevance of each recommendation by computing the number of relevant keywords it contains\n",
    "        in relation to the query and then averaging out this measure across the entire query set.\n",
    "    '''\n",
    "    word_stats_p_at_k = {}\n",
    "    avg_p_at_k = {}\n",
    "\n",
    "    # Loop through results\n",
    "    for i in range(results.shape[1]):\n",
    "\n",
    "            # Isolate the measured closeness to all vectors in the course matrix\n",
    "            top_k_recs = np.argsort(results[:,i])[:-k-1:-1]\n",
    "#             print(top_k_recs)\n",
    "            \n",
    "            # Extract keywords in query\n",
    "            test_words = test_keywords[i][1]\n",
    "#             print(f\"Test subject: {test_words}, {len(test_words)}\")\n",
    "\n",
    "            # Extract keywords in recommendation\n",
    "            rec_words = [training_keywords[rec][1] for rec in top_k_recs]\n",
    "    #         print(f\"Rec subject: {rec_words}\")\n",
    "            \n",
    "            # Create variable to hold results\n",
    "            word_stats_p_at_k[i] = []\n",
    "            # https://stackoverflow.com/questions/1388818/how-can-i-compare-two-lists-in-python-and-return-matches\n",
    "            for rec in rec_words:\n",
    "#                 print(f\"Set: {set(test_words) & set(rec)}\")\n",
    "#                 print(rec)\n",
    "                # Count the number of words that are relevant of the entire number of words\n",
    "                #  returned in each recommendation\n",
    "                word_stats_p_at_k[i].append(len(set(test_words) & set(rec))/len(rec))\n",
    "            \n",
    "            # Average out this measure across k recommendations\n",
    "            avg_p_at_k[i] = sum(word_stats_p_at_k[i])/k\n",
    "   \n",
    "    return avg_p_at_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd37721-126e-4dcc-8258-522afe36b929",
   "metadata": {},
   "source": [
    "### *Process Test Set* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18717c10-acc8-47f8-b04f-83ccb84e90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process similarity of test keywords to known keywords\n",
    "results = CB_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b977d-fa3b-4a39-9728-3960e4ab93be",
   "metadata": {},
   "source": [
    "### *Calculate Percetange of Correct Subject Attirbution* ###\n",
    "Because the courses in the test and training sets are different, the keywords for one course will never match another in their entirety unless a course has been acidentally miscategorized using a different course code or unless its course code has been modified over time. (These are very few instances in this paritcular dataset where it appears that the course providers decided to make a slight modification the course code of a subsequent offering.) However, it seems to me to be nevertheless useful to check the extent to which the keyword search yields courses in the same category because it gives us a measure not only of the extent to which the algoirthm works to narrow down recommendations but also the way in which this algorithm includes elements of serendipity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abfe1838-d0d1-4029-a67d-c8ad1af626e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy at 1: 1.0\n",
      "Average accuracy at 2: 0.9736842105263158\n",
      "Average accuracy at 3: 0.9473684210526315\n",
      "Average accuracy at 4: 0.9210526315789473\n",
      "Average accuracy at 5: 0.9263157894736843\n",
      "Average accuracy at 6: 0.9210526315789473\n",
      "Average accuracy at 7: 0.9172932330827067\n",
      "Average accuracy at 8: 0.9013157894736842\n",
      "Average accuracy at 9: 0.9005847953216374\n",
      "Average accuracy at 10: 0.9052631578947368\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    n=i+1\n",
    "    accuracy = CB_subject_accuracy_at_k(results, n=n)\n",
    "\n",
    "#     print(accuracy)\n",
    "    print(f\"Average accuracy at {n}: {sum(accuracy[n].values())/len(accuracy[n])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8cfcb-5d46-40ee-a2e9-a1b05df8f046",
   "metadata": {},
   "source": [
    "The decrease in this accuracy measure tells us, in effect, that the correct categories emerge within the first few recommendations and that opening up the recommender to more options can make it perform less optimally. Another way to phrase this would be to say that as the number of recommendations we ask it to generate increases, the system introduces more serendipity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b0999-52a4-4234-9447-f18a04a19f31",
   "metadata": {},
   "source": [
    "### *Precision at K* ###\n",
    "Because a CB subsystem focused on finding proximity of keywords returns items that are relevant on a scale, I have decided to use precision as a way to measure the relevance of what is returned, but to do so by calculating the precision of the words returned by every recommendation and to average that out over *k* recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17fad899-e583-4cfa-9f90-53fb3fd5eadb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Precision at 1 for each sample:\n",
      "{0: 0.8571428571428571, 1: 0.8, 2: 1.0, 3: 0.4, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.7777777777777778, 8: 1.0, 9: 0.5, 10: 0.4444444444444444, 11: 1.0, 12: 0.4444444444444444, 13: 0.3333333333333333, 14: 0.6666666666666666, 15: 0.5454545454545454, 16: 1.0, 17: 0.5, 18: 1.0} \n",
      "\n",
      "Average precision at k=1: 0.7246981089086352\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 2 for each sample:\n",
      "{0: 0.8571428571428571, 1: 0.6857142857142857, 2: 0.8333333333333333, 3: 0.3666666666666667, 4: 0.8333333333333333, 5: 0.5892857142857143, 6: 0.7083333333333333, 7: 0.7638888888888888, 8: 0.6666666666666666, 9: 0.5, 10: 0.4222222222222222, 11: 1.0, 12: 0.4222222222222222, 13: 0.3333333333333333, 14: 0.6666666666666666, 15: 0.5852272727272727, 16: 1.0, 17: 0.35, 18: 1.0} \n",
      "\n",
      "Average precision at k=2: 0.6623177261335156\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 3 for each sample:\n",
      "{0: 0.8571428571428571, 1: 0.6238095238095238, 2: 0.7555555555555555, 3: 0.35555555555555557, 4: 0.6507936507936507, 5: 0.5595238095238095, 6: 0.5388888888888889, 7: 0.8425925925925926, 8: 0.5555555555555555, 9: 0.4444444444444444, 10: 0.4148148148148148, 11: 1.0, 12: 0.4148148148148148, 13: 0.3333333333333333, 14: 0.5555555555555555, 15: 0.6568181818181819, 16: 0.8333333333333334, 17: 0.28888888888888886, 18: 0.9166666666666666} \n",
      "\n",
      "Average precision at k=3: 0.6104256854256854\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 4 for each sample:\n",
      "{0: 0.8095238095238094, 1: 0.5035714285714286, 2: 0.7095238095238094, 3: 0.32916666666666666, 4: 0.5714285714285714, 5: 0.5446428571428572, 6: 0.5291666666666666, 7: 0.8819444444444444, 8: 0.47916666666666663, 9: 0.41666666666666663, 10: 0.33611111111111114, 11: 0.95, 12: 0.33611111111111114, 13: 0.3333333333333333, 14: 0.49999999999999994, 15: 0.6926136363636364, 16: 0.725, 17: 0.3416666666666667, 18: 0.8125} \n",
      "\n",
      "Average precision at k=4: 0.5685335497835498\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 5 for each sample:\n",
      "{0: 0.7476190476190475, 1: 0.46952380952380957, 2: 0.6533333333333332, 3: 0.2996969696969697, 4: 0.5071428571428571, 5: 0.5023809523809525, 6: 0.5033333333333332, 7: 0.8388888888888889, 8: 0.45, 9: 0.39999999999999997, 10: 0.33555555555555555, 11: 0.9199999999999999, 12: 0.33555555555555555, 13: 0.3333333333333333, 14: 0.4666666666666666, 15: 0.6874242424242424, 16: 0.6599999999999999, 17: 0.37333333333333335, 18: 0.73} \n",
      "\n",
      "Average precision at k=5: 0.5375677830940988\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 6 for each sample:\n",
      "{0: 0.7063492063492062, 1: 0.44682539682539685, 2: 0.6277777777777777, 3: 0.28005050505050505, 4: 0.4781746031746032, 5: 0.4742063492063493, 6: 0.4402777777777777, 7: 0.8101851851851852, 8: 0.4166666666666667, 9: 0.375, 10: 0.3351851851851852, 11: 0.8878787878787878, 12: 0.3351851851851852, 13: 0.3333333333333333, 14: 0.4444444444444444, 15: 0.6561868686868687, 16: 0.5916666666666667, 17: 0.3666666666666667, 18: 0.6749999999999999} \n",
      "\n",
      "Average precision at k=6: 0.5095295055821373\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 7 for each sample:\n",
      "{0: 0.6530612244897958, 1: 0.43061224489795924, 2: 0.6095238095238094, 3: 0.2579004329004329, 4: 0.445578231292517, 5: 0.45408163265306134, 6: 0.413095238095238, 7: 0.7230158730158731, 8: 0.40476190476190477, 9: 0.35714285714285715, 10: 0.32301587301587303, 11: 0.864935064935065, 12: 0.32301587301587303, 13: 0.3333333333333333, 14: 0.42857142857142855, 15: 0.6338744588744589, 16: 0.5428571428571428, 17: 0.36190476190476195, 18: 0.6261904761904761} \n",
      "\n",
      "Average precision at k=7: 0.4834985190248348\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 8 for each sample:\n",
      "{0: 0.6130952380952379, 1: 0.418452380952381, 2: 0.5958333333333332, 3: 0.2395517676767677, 4: 0.43154761904761907, 5: 0.42857142857142866, 6: 0.39270833333333327, 7: 0.695138888888889, 8: 0.3854166666666667, 9: 0.34375, 10: 0.32430555555555557, 11: 0.8068181818181819, 12: 0.32430555555555557, 13: 0.3333333333333333, 14: 0.4166666666666667, 15: 0.5754734848484849, 16: 0.5166666666666666, 17: 0.3583333333333334, 18: 0.5895833333333332} \n",
      "\n",
      "Average precision at k=8: 0.46260798777246137\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 9 for each sample:\n",
      "{0: 0.5820105820105819, 1: 0.4089947089947091, 2: 0.5666666666666665, 3: 0.2684904601571268, 4: 0.4206349206349207, 5: 0.40873015873015883, 6: 0.38611111111111107, 7: 0.6734567901234568, 8: 0.3703703703703704, 9: 0.3333333333333333, 10: 0.3160493827160494, 11: 0.744949494949495, 12: 0.3160493827160494, 13: 0.3333333333333333, 14: 0.40740740740740744, 15: 0.5337542087542089, 16: 0.49629629629629624, 17: 0.3462962962962963, 18: 0.5518518518518518} \n",
      "\n",
      "Average precision at k=9: 0.445515092444917\n",
      "-------------------------------------------------------------------------\n",
      "Precision at 10 for each sample:\n",
      "{0: 0.5488095238095236, 1: 0.4014285714285715, 2: 0.5433333333333332, 3: 0.29164141414141415, 4: 0.40357142857142864, 5: 0.3928571428571429, 6: 0.3760714285714285, 7: 0.6394444444444445, 8: 0.35833333333333334, 9: 0.33333333333333337, 10: 0.3177777777777778, 11: 0.6935314685314686, 12: 0.3177777777777778, 13: 0.33333333333333337, 14: 0.4, 15: 0.4880710955710956, 16: 0.4666666666666666, 17: 0.3366666666666667, 18: 0.5252380952380952} \n",
      "\n",
      "Average precision at k=10: 0.4298887808098335\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):    \n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(f\"Precision at {k+1} for each sample:\")\n",
    "    p = CB_precision_at_k(results, k+1)\n",
    "    \n",
    "    print(p,'\\n')\n",
    "    avg_p = sum(p.values())/len(p.values())\n",
    "    print(f\"Average precision at k={k+1}: {avg_p}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8796d439-f3a7-4b01-9a9d-23235cca29b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Full Result Printout ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7640b546-ae6b-4515-8787-3319c0823fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Test_keywords 0: \n",
      "(183, ['religions', 'scriptures', 'hinduism', 'through', 'their', 'world', 'hhdre']) HDS3221.5x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(166, ['religions', 'christianity', 'scriptures', 'through', 'their', 'world', 'hhdre']) HDS3221.2x\n",
      "(173, ['religions', 'scriptures', 'through', 'their', 'world', 'buddhism', 'hhdre']) HDS3221.3x\n",
      "(178, ['religions', 'islam', 'scriptures', 'through', 'their', 'world', 'hhdre']) HDS3221.4x\n",
      "(162, ['religions', 'traditions', 'religious', 'literacy', 'scriptures', 'through', 'their', 'world', 'hhdre']) HDS3221.1x\n",
      "(55, ['justice', 'hhdre']) ER22x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 1: \n",
      "(174, ['solids', 'applications', 'nature', 'cellular', 'stem']) 3.054.3x MITx\n",
      "\n",
      "Recommendations:\n",
      "(168, ['solids', 'medicine', 'applications', 'cellular', 'stem']) 3.054.2x\n",
      "(159, ['properties', 'solids', 'applications', 'structures', 'engineering', 'cellular', 'stem']) 3.054.1x\n",
      "(139, ['circuits', 'electronics', 'applications', 'stem']) 6.002.3x\n",
      "(99, ['nature', 'america', 'american', 'nation', '1700-1850', 'poetry', 'hhdre']) AMPOx.2\n",
      "(138, ['aerodynamics', 'introduction', 'stem']) 16.101x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 2: \n",
      "(145, ['materials', 'beams', 'mechanical', 'solids', 'transformations', 'behavior', 'stress', 'columns', 'cellular', 'stem']) 3.032.2x MITx\n",
      "\n",
      "Recommendations:\n",
      "(88, ['mechanical', 'materials', 'behavior', 'stem']) 3.032x\n",
      "(125, ['materials', 'mechanical', 'linear', 'behavior', 'elastic', 'stem']) 3.032.1x\n",
      "(168, ['solids', 'medicine', 'applications', 'cellular', 'stem']) 3.054.2x\n",
      "(148, ['time', 'materials', 'mechanical', 'behavior', 'failure', 'dependent', 'stem']) 3.032.3x\n",
      "(159, ['properties', 'solids', 'applications', 'structures', 'engineering', 'cellular', 'stem']) 3.054.1x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 3: \n",
      "(63, ['national', 'culture', 'new', 'hhdre']) SW12.4x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(64, ['culture', 'cosmopolitan', 'tang', 'aristocratic', 'hhdre']) SW12.3x\n",
      "(90, ['america', 'early', 'new', 'england', 'poetry', 'hhdre']) AMPOx.1\n",
      "(75, ['america', 'early', 'new', 'england', 'poetry', 'hhdre']) AI12.1x\n",
      "(92, ['immunity', 'change', 'new', 'personal', 'approach', 'improvement', 'unlocking', 'hhdre']) GSE1.1x\n",
      "(142, ['accountability', 'standards', 'national', 'education', 'politics', 'policy', 'schools', 'history', 'saving', 'us', 'hhdre']) GOV1368.3x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 4: \n",
      "(126, ['self', 'transforming', 'business', 'society', 'ghss']) 15.671x MITx\n",
      "\n",
      "Recommendations:\n",
      "(106, ['self', 'transforming', 'business', 'society', 'ghss']) 15.S23x\n",
      "(76, ['society', 'health', 'ghss']) PH201x\n",
      "(169, ['money', 'mattered', 'just', 'society', 'if', 'banking', 'ghss']) 11.405x\n",
      "(45, ['bioconductor', 'introduction', 'ghss']) PH525.4x\n",
      "(82, ['data', 'analysis', 'genomics', 'ghss']) PH525x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 5: \n",
      "(184, ['fantastique', 'first', 'nights', 'symphonie', 'hhdre']) MUS24.4x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(172, ['lorfeo', 'first', 'nights', 'hhdre']) MUS24.1x\n",
      "(19, ['messiah', 'nights', 'handels', 'first', 'baroque', 'oratorio', 'hhdre']) MUS24x\n",
      "(84, ['justice', 'hhdre']) ER22.1x\n",
      "(55, ['justice', 'hhdre']) ER22x\n",
      "(8, ['architecture', 'global', 'hhdre']) 4.605x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 6: \n",
      "(156, ['care', 'health', 'practical', 'science', 'improvement', 'getting', 'roadmap', 'results', 'ghss']) PH556x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(52, ['care', 'innovating', 'health', 'ghss']) BUS5.1x\n",
      "(76, ['society', 'health', 'ghss']) PH201x\n",
      "(122, ['your', 'work', 'practical', 'science', 'pictures', 'guide', 'presenting', 'making', 'engineering', 'stem']) 0.111x\n",
      "(157, ['readings', 'health', 'global', 'ghss']) PH231x\n",
      "(83, ['policy', 'united', 'health', 'states', 'ghss']) HSPH210x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 7: \n",
      "(91, ['greek', 'hero', 'signs', 'epic', 'iconography', 'hours', '6-11', '24', 'ancient', 'hhdre']) HUM2.2x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(87, ['greek', 'hero', '1-5', 'epic', 'lyric', 'hours', '24', 'ancient', 'hhdre']) HUM2.1x\n",
      "(98, ['greek', 'hero', '16-21', 'hours', 'tragedy', '24', 'ancient', 'hhdre']) HUM2.4x\n",
      "(70, ['greek', 'hero', 'ancient', 'hhdre']) CB22.1x\n",
      "(68, ['greek', 'hero', 'ancient', 'hhdre']) CB22x\n",
      "(97, ['greek', 'hero', 'heroes', 'cult', 'hours', '12-15', '24', 'ancient', 'hhdre']) HUM2.3x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 8: \n",
      "(181, ['becoming', 'entrepreneur', 'ghss']) LAUNCHx MITx\n",
      "\n",
      "Recommendations:\n",
      "(158, ['becoming', 'entrepreneur', 'ghss']) LAUNCH.x\n",
      "(76, ['society', 'health', 'ghss']) PH201x\n",
      "(45, ['bioconductor', 'introduction', 'ghss']) PH525.4x\n",
      "(82, ['data', 'analysis', 'genomics', 'ghss']) PH525x\n",
      "(54, ['commercialization', 'innovation', 'ghss']) 3.086x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 9: \n",
      "(23, ['communist', 'liberations', 'hhdre']) SW12.9x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(84, ['justice', 'hhdre']) ER22.1x\n",
      "(55, ['justice', 'hhdre']) ER22x\n",
      "(8, ['architecture', 'global', 'hhdre']) 4.605x\n",
      "(31, ['learning', 'leaders', 'hhdre']) GSE2x\n",
      "(51, ['empire', 'last', 'hhdre']) SW12.6x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 10: \n",
      "(80, ['101', 'your', 'entrepreneurship', 'customer', 'is', 'who', 'ghss']) 15.390x MITx\n",
      "\n",
      "Recommendations:\n",
      "(33, ['your', 'you', '102', 'entrepreneurship', 'what', 'customer', 'can', 'do', 'ghss']) 15.390.2x\n",
      "(119, ['entrepreneurship', 'user', 'innovation', 'path', 'ghss']) UINOV8x\n",
      "(101, ['emerging', 'healthcare', 'entrepreneurship', 'economies', 'ghss']) SW47.1x\n",
      "(122, ['your', 'work', 'practical', 'science', 'pictures', 'guide', 'presenting', 'making', 'engineering', 'stem']) 0.111x\n",
      "(76, ['society', 'health', 'ghss']) PH201x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 11: \n",
      "(143, ['choice', 'education', 'politics', 'policy', 'school', 'schools', 'history', 'saving', 'us', 'hhdre']) GOV1368.4x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(108, ['education', 'politics', 'policy', 'schools', 'history', 'saving', 'us', 'hhdre']) 1368.4x\n",
      "(89, ['education', 'politics', 'policy', 'schools', 'history', 'saving', 'us', 'hhdre']) 1368.1x\n",
      "(140, ['education', 'politics', 'policy', 'schools', 'history', 'saving', 'us', 'hhdre']) GOV1368.1x\n",
      "(141, ['education', 'politics', 'policy', 'teacher', 'policies', 'schools', 'history', 'saving', 'us', 'hhdre']) GOV1368.2x\n",
      "(100, ['education', 'politics', 'policy', 'teacher', 'policies', 'schools', 'history', 'saving', 'us', 'hhdre']) 1368.2x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 12: \n",
      "(32, ['101', 'your', 'entrepreneurship', 'customer', 'is', 'who', 'ghss']) 15.390.1x MITx\n",
      "\n",
      "Recommendations:\n",
      "(33, ['your', 'you', '102', 'entrepreneurship', 'what', 'customer', 'can', 'do', 'ghss']) 15.390.2x\n",
      "(119, ['entrepreneurship', 'user', 'innovation', 'path', 'ghss']) UINOV8x\n",
      "(101, ['emerging', 'healthcare', 'entrepreneurship', 'economies', 'ghss']) SW47.1x\n",
      "(122, ['your', 'work', 'practical', 'science', 'pictures', 'guide', 'presenting', 'making', 'engineering', 'stem']) 0.111x\n",
      "(76, ['society', 'health', 'ghss']) PH201x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 13: \n",
      "(67, ['magnetism', 'electricity', 'stem']) 8.02x MITx\n",
      "\n",
      "Recommendations:\n",
      "(138, ['aerodynamics', 'introduction', 'stem']) 16.101x\n",
      "(2, ['circuits', 'electronics', 'stem']) 6.002x\n",
      "(71, ['mechanics', 'classical', 'stem']) 8.01x\n",
      "(53, ['mechanics', 'review', 'stem']) 8.MREV\n",
      "(74, ['control', 'dynamics', 'stem']) 2.03x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 14: \n",
      "(165, ['coordinate', 'series', 'calculus', 'infinite', 'systems', 'stem']) 18.01.3x MITx\n",
      "\n",
      "Recommendations:\n",
      "(152, ['integration', 'calculus', 'stem']) 18.01.2x\n",
      "(120, ['differentiation', 'calculus', 'stem']) 18.01.1x\n",
      "(138, ['aerodynamics', 'introduction', 'stem']) 16.101x\n",
      "(2, ['circuits', 'electronics', 'stem']) 6.002x\n",
      "(71, ['mechanics', 'classical', 'stem']) 8.01x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 15: \n",
      "(149, ['interactions', 'physics', 'atom-light', 'optical', 'field', 'matrix', 'quantized', 'atomic', 'elements', '1', 'stem']) 8.421.3x MITx\n",
      "\n",
      "Recommendations:\n",
      "(154, ['interactions', 'physics', 'two-photon', 'atom-light', '2', 'optical', 'broadening', 'line', 'atomic', 'transitions', 'stem']) 8.421.4x\n",
      "(146, ['physics', 'atoms', 'optical', 'external', 'atomic', 'structure', 'field', 'stem']) 8.421.2x\n",
      "(155, ['optical', 'physics', 'atomic', 'coherence', 'stem']) 8.421.5x\n",
      "(137, ['optical', 'physics', 'atomic', 'resonance', 'stem']) 8.421.1x\n",
      "(16, ['structures', 'elements', 'stem']) 2.01x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 16: \n",
      "(41, ['computer', 'programming', 'science', 'introduction', 'cs']) 6.00x MITx\n",
      "\n",
      "Recommendations:\n",
      "(0, ['computer', 'programming', 'science', 'introduction', 'cs']) 6.00.1x\n",
      "(4, ['computer', 'science', 'introduction', 'cs']) CS50x\n",
      "(3, ['data', 'science', 'thinking', 'computational', 'introduction', 'cs']) 6.00.2x\n",
      "(150, ['structures', 'computer', 'computation', 'architecture', 'cs']) 6.004.2x\n",
      "(13, ['science', 'probability', 'introduction', 'uncertainty', 'stem']) 6.041x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 17: \n",
      "(79, ['unlocking', 'change', 'immunity', 'hhdre']) GSE1x HarvardX\n",
      "\n",
      "Recommendations:\n",
      "(92, ['immunity', 'change', 'new', 'personal', 'approach', 'improvement', 'unlocking', 'hhdre']) GSE1.1x\n",
      "(113, ['change', 'juryx', 'deliberations', 'social', 'ghss']) HLS3x\n",
      "(69, ['health', 'change', 'human', 'global', 'environmental', 'ghss']) PH278x\n",
      "(55, ['justice', 'hhdre']) ER22x\n",
      "(84, ['justice', 'hhdre']) ER22.1x\n",
      "-------------------------------------------------------------------------\n",
      "Test_keywords 18: \n",
      "(116, ['materials', 'devices', 'magnetic', 'optical', 'electrical', 'stem']) 3.15x MITx\n",
      "\n",
      "Recommendations:\n",
      "(187, ['materials', 'devices', 'magnetic', 'stem']) 3.15.3x\n",
      "(182, ['optical', 'materials', 'devices', 'stem']) 3.15.2x\n",
      "(177, ['materials', 'devices', 'electronic', 'stem']) 3.15.1x\n",
      "(88, ['mechanical', 'materials', 'behavior', 'stem']) 3.032x\n",
      "(137, ['optical', 'physics', 'atomic', 'resonance', 'stem']) 8.421.1x\n"
     ]
    }
   ],
   "source": [
    "CB_tabulate_results(results, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf4553-4c78-4eaf-bf91-e145f2638efc",
   "metadata": {},
   "source": [
    "# Recommender Interface #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "dd486bc1-9248-4bae-829b-dcf2dd1afb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User template\n",
    "user_template = {\n",
    "    \n",
    "    # CF Component\n",
    "    \"CF\" : {    \n",
    "#             // userid that is not in the system\n",
    "            },\n",
    "    # CB Component\n",
    "    \"CB\":{\n",
    "#             \"subject\": \"\",\n",
    "#             \"keywords\": []\n",
    "\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ac4b7-5bcb-4c46-9558-cf8acebac7d6",
   "metadata": {},
   "source": [
    "### *Define 3 Sample Users* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d641de84-971e-432b-9acc-bbd8d5dd745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user1 = {\n",
    "    \"CF\":{},\n",
    "    \"CB\":{}\n",
    "}\n",
    "\n",
    "test_user2 = {\n",
    "    \"CF\":{\n",
    "      \"userid\": \"M130597645\"\n",
    "    },\n",
    "    \"CB\":{\n",
    "          \"subject\":\"ghss\",\n",
    "        \"keywords\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "test_user3 = {\n",
    "    \"CF\":{\n",
    "          \"userid\": \"M130597666\"\n",
    "    },\n",
    "    \"CB\":{\n",
    "          \"subject\":\"cs\",\n",
    "        \"keywords\": [\"programming\", \"python\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f3530b35-fb58-4f89-8fe5-ccdbfa6fb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_recommender(user_object):\n",
    "    '''\n",
    "        Function that can access both elements of the hybrid recommender and does so \n",
    "        based on which information is provided by the user.\n",
    "        \n",
    "        Inputs:\n",
    "        - user_object: information about the user\n",
    "        \n",
    "        Otputs:\n",
    "        - printout of recommendations\n",
    "    '''\n",
    "    \n",
    "\n",
    "    user_object = user_object.copy()\n",
    "    \n",
    "    # User has stated no preference\n",
    "    if (user_object[\"CB\"] == {}):\n",
    "        # Supply blank subject and keyword categories in order\n",
    "        #   to elicit recommendations based on stats\n",
    "        user_object[\"CB\"] = {\n",
    "            \"subject\": \"\",\n",
    "            \"keywords\": []\n",
    "        }\n",
    "        print(f\"Courses with highest completion rates on our system: {CB_recommender(user_object['CB'])}\")\n",
    "        for course in CB_recommender(user_object['CB']):\n",
    "            print(CB_train_df.loc[CB_train_df[\"Course Number\"]==course, CB_train_df.columns[1:3]])\n",
    "  \n",
    "    elif user_object[\"CB\"][\"keywords\"]==[]:\n",
    "        courses = CB_recommender(user_object['CB'])\n",
    "        print(f\"Courses with highest completeion rates in your chosen subject: {courses[courses.columns[1:3]]}\")\n",
    "    \n",
    "    else:\n",
    "        idxs = CB_recommender(user_object['CB'])\n",
    "        print(f\"Courses that might be of interest:\")\n",
    "        print(CB_train_df.iloc[idxs, 1:3])\n",
    "#         print(CB_recs)\n",
    "        \n",
    "    \n",
    "    # Cold-start scenario\n",
    "    if (user_object[\"CF\"] == {}):\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Your personalized course recommendations are as follows: {CF_recommender(user_object['CF']['userid'])}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde6564-472f-4145-bb9d-6c8cbc9466ab",
   "metadata": {},
   "source": [
    "### *Define 3 Sample Users* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "723d7fe2-b5dd-4fc9-ad4e-e08415d917ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses with highest completion rates on our system: {'HUM1.7x': None, '1368.3x': None, 'HUM2.3x': None, '1368.4x': None, 'GOV1368.3x': None}\n",
      "    Course Number                                       Course Title\n",
      "133       HUM1.7x  History of the Book: Monasteries, Schools, and...\n",
      "    Course Number                                       Course Title\n",
      "104       1368.3x  Saving Schools: History, Politics, and Policy ...\n",
      "   Course Number                                       Course Title\n",
      "97       HUM2.3x  The Ancient Greek Hero in 24 Hours (Hours 12-1...\n",
      "    Course Number                                       Course Title\n",
      "108       1368.4x  Saving Schools: History, Politics, and Policy ...\n",
      "    Course Number                                       Course Title\n",
      "142    GOV1368.3x  Saving Schools: History, Politics, and Policy ...\n"
     ]
    }
   ],
   "source": [
    "access_recommender(test_user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "8cf8b36a-689b-4b78-a0d4-76450432cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses with highest completeion rates in your chosen subject:     Course Number                                       Course Title\n",
      "153        PH557x   Lessons from Ebola: Preventing the Next Pandemic\n",
      "93         PH555x  Improving Global Health: Focusing on Quality a...\n",
      "76         PH201x                                 Health and Society\n",
      "61          SW25x  Global Health: Case Studies from a Biosocial P...\n",
      "86       MAS.S69x                        Big Data and Social Physics\n",
      "Your personalized course recommendations are as follows: {'ER22x': (44.0, 1, 0.22797927461139897), '6.00x': (37.0, 2, 0.19170984455958548), '14.73x': (35.0, 3, 0.18134715025906736), 'CB22x': (14.0, 4, 0.07253886010362694), '3.091x': (14.0, 5, 0.07253886010362694)}\n"
     ]
    }
   ],
   "source": [
    "access_recommender(test_user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "127a80f5-2b07-4dc8-a8b1-242aade256e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokesn 1: ['programming', 'python']\n",
      "tokens: ['programming', 'python', 'cs']\n",
      "Courses that might be of interest:\n",
      "    Course Number                                      Course Title\n",
      "0         6.00.1x  Introduction to Computer Science and Programming\n",
      "4           CS50x                  Introduction to Computer Science\n",
      "14       21W.789x                       Building Mobile Experiences\n",
      "150      6.004.2x     Computation Structures: Computer Architecture\n",
      "49       6.004.1x          Computation Structures: Digital Circuits\n",
      "Your personalized course recommendations are as follows: {'PH207x': (41.0, 1, 0.23563218390804597), '6.002x': (38.0, 2, 0.21839080459770116), '14.73x': (23.0, 3, 0.13218390804597702), 'ER22x': (18.0, 4, 0.10344827586206896), 'CS50x': (9.0, 5, 0.05172413793103448)}\n"
     ]
    }
   ],
   "source": [
    "access_recommender(test_user3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb77cda-b940-4ff8-90a4-97b16221f0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
